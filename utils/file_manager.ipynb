{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import minetext.visualization.wordcloud_visualization as visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_directory(dirpath):\n",
    "    if os.path.exists(dirpath):\n",
    "        shutil.rmtree(dirpath, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_file(dirpath, filename, header=0, index_col=None, encoding=\"UTF-8\", quoting=csv.QUOTE_NONNUMERIC):\n",
    "    filepath = os.path.join(dirpath, filename)\n",
    "    \n",
    "    return pd.read_csv(filepath_or_buffer=filepath,\\\n",
    "                       index_col=index_col,\\\n",
    "                       header=header,\\\n",
    "                       encoding=encoding,\\\n",
    "                       quoting=quoting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_directory(dirpath, header=0, encoding=\"UTF-8\", quoting=csv.QUOTE_NONNUMERIC):\n",
    "    dataframes = []\n",
    "    \n",
    "    files = os.listdir(dirpath)\n",
    "    \n",
    "    for file in files:    \n",
    "        filename = os.fsdecode(file)\n",
    "        \n",
    "        if filename.endswith(\".csv\"):\n",
    "            dataframe = read_csv_file(dirpath=dirpath, filename=filename, header=header, encoding=encoding, quoting=quoting)\n",
    "            \n",
    "            dataframes.append(dataframe)\n",
    "            \n",
    "    return pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_csv(data, dirpath, filename, index=True, index_label=\"index\", columns=None, header=True, encoding=\"UTF-8\", quoting=csv.QUOTE_NONNUMERIC):\n",
    "    create_directory(dirpath)\n",
    "    \n",
    "    filepath = os.path.join(dirpath, filename)\n",
    "    \n",
    "    output = pd.DataFrame(data=data, columns=columns)\n",
    "    \n",
    "    output.to_csv(path_or_buf=filepath, index=index, index_label=index_label, header=header, encoding=encoding, quoting=quoting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_results_to_csv(results, dirpath, filename, columns=None):\n",
    "    data_to_csv(data=results, dirpath=dirpath, filename=filename, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusters_to_csv(result, dirpath, collection_field, header=True, columns=None, encoding=\"UTF-8\"):\n",
    "    clustering_dirpath = os.path.join(dirpath, \"clustering\")\n",
    "    \n",
    "    # result: k, sse, iteractions, clusters\n",
    "    for index, k in enumerate(result[\"k\"]):\n",
    "        iteraction = result[\"iteraction\"][index]\n",
    "        clusters = result[\"clusters\"][index]\n",
    "        \n",
    "        subdir_clusters = os.path.join(clustering_dirpath,\\\n",
    "                                       \"K_\" + str(k),\\\n",
    "                                       \"iteraction_\" + str(iteraction),\\\n",
    "                                       \"clusters\")\n",
    "        \n",
    "        create_directory(subdir_clusters)\n",
    "        \n",
    "        for cluster in clusters:\n",
    "            cluster_id = cluster[\"id\"]\n",
    "            cluster_documents = cluster[collection_field]\n",
    "            \n",
    "            cluster_filename = \"cluster_\" + str(cluster_id) + \".csv\"\n",
    "            \n",
    "            # Salva o cluster\n",
    "            data_to_csv(data=cluster_documents, filename=cluster_filename, dirpath=subdir_clusters, header=header, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_to_csv(result, dirpath, header=True, encoding=\"UTF-8\"):\n",
    "    clustering_dirpath = os.path.join(dirpath, \"clustering\")\n",
    "    \n",
    "    # result: k, iteractions, clusters, most_similar\n",
    "    for index, k in enumerate(result[\"k\"]):\n",
    "        iteraction = result[\"iteraction\"][index]\n",
    "        clusters = result[\"clusters\"][index]\n",
    "        most_similar = result[\"most_similar\"][index]\n",
    "        \n",
    "        subdir_most_similar = os.path.join(clustering_dirpath,\\\n",
    "                                           \"K_\" + str(k),\\\n",
    "                                           \"iteraction_\" + str(iteraction),\\\n",
    "                                           \"most_similar\")\n",
    "        \n",
    "        create_directory(subdir_most_similar)\n",
    "        \n",
    "        for cluster in clusters:\n",
    "            cluster_id = cluster[\"id\"]\n",
    "            cluster_most_similar = []\n",
    "            \n",
    "            cluster_most_similar_filename = \"most_similar_cluster_\" + str(cluster_id) + \".csv\"                      \n",
    "            \n",
    "            for distance, document in most_similar[cluster_id]:\n",
    "                similar = dict()\n",
    "                \n",
    "                similar[\"content\"] = document[\"content\"]\n",
    "                similar[\"clean_content\"] = document[\"clean_content\"]\n",
    "                similar[\"cluster\"] = document[\"cluster\"]\n",
    "                similar[\"distance\"] = distance\n",
    "                \n",
    "                cluster_most_similar.append(similar)\n",
    "            \n",
    "            # Salva os n documentos mais similares do cluster\n",
    "            data_to_csv(data=cluster_most_similar,\\\n",
    "                        filename=cluster_most_similar_filename,\\\n",
    "                        dirpath=subdir_most_similar,\\\n",
    "                        header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def medoids_to_csv(result, dirpath, encoding=\"UTF-8\"):\n",
    "    clustering_dirpath = os.path.join(dirpath, \"clustering\")\n",
    "    \n",
    "    medoids_filename = \"clusters_medoids.csv\"\n",
    "    \n",
    "    # result: k, sse, iteractions, clusters\n",
    "    for index, k in enumerate(result[\"k\"]):\n",
    "        iteraction = result[\"iteraction\"][index]\n",
    "        medoids = result[\"medoids\"][index]\n",
    "        \n",
    "        subdir_iteraction = os.path.join(clustering_dirpath,\\\n",
    "                                       \"K_\" + str(k),\\\n",
    "                                       \"iteraction_\" + str(iteraction))\n",
    "        \n",
    "        create_directory(subdir_iteraction)\n",
    "        \n",
    "        # Salva o cluster\n",
    "        data_to_csv(data=medoids, filename=medoids_filename, dirpath=subdir_iteraction, encoding=encoding, columns=[\"content\", \"clean_content\", \"rating\", \"cluster\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusters_to_wordcloud(result, dirpath, collection_field, text_field_name, filename_preffix=\"wordcloud_cluster\"):\n",
    "    clustering_dirpath = os.path.join(dirpath, \"clustering\")\n",
    "    \n",
    "    # result: k, iteraction, clusters\n",
    "    for index, k in enumerate(result[\"k\"]):\n",
    "        clusters = result[\"clusters\"][index]\n",
    "        iteraction = result[\"iteraction\"][index]\n",
    "\n",
    "        subdir_wordclouds = os.path.join(clustering_dirpath,\\\n",
    "                                         \"K_\" + str(k),\\\n",
    "                                         \"iteraction_\" + str(iteraction),\\\n",
    "                                         \"wordclouds\")\n",
    "\n",
    "        create_directory(subdir_wordclouds)\n",
    "\n",
    "        filepath = os.path.join(subdir_wordclouds, filename_preffix)\n",
    "        \n",
    "        visualization.generate_pure_word_cloud_from_clusters(save_dir_file=filepath,\\\n",
    "                                                             clusters=clusters,\\\n",
    "                                                             collection_field=collection_field,\\\n",
    "                                                             text_field_name=text_field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusters_dataframe_from_csv(result_dirpath, k=None, k_preffix=\"K_\", iteraction=None, iteraction_preffix=\"iteraction_\"):\n",
    "    clustering_dirpath = os.path.join(result_dirpath, \"clustering\")\n",
    "    \n",
    "    clusters = []\n",
    "    \n",
    "    if k:\n",
    "        k_subdirs = [k_preffix + str(k)]\n",
    "    else:\n",
    "        k_subdirs = os.listdir(clustering_dirpath)\n",
    "    \n",
    "    for k_subdir in k_subdirs:\n",
    "        k_subdirpath = os.path.join(clustering_dirpath, k_subdir)\n",
    "        \n",
    "        if os.path.isdir(k_subdirpath):\n",
    "            if iteraction:\n",
    "                itr_subdirs = [iteraction_preffix + str(iteraction)]\n",
    "            else:\n",
    "                itr_subdirs = os.listdir(k_subdirpath)\n",
    "            \n",
    "            for itr_subdir in itr_subdirs:\n",
    "                itr_subdirpath = os.path.join(k_subdirpath, itr_subdir)\n",
    "                \n",
    "                if os.path.isdir(itr_subdirpath):\n",
    "                    clusters_subdirpath = os.path.join(itr_subdirpath, \"clusters\")\n",
    "                    \n",
    "                    # Extrai o valor de K do nome das pastas (P.O.G)\n",
    "                    k = int(k_subdir.replace(\"K_\", \"\"))\n",
    "                \n",
    "                    # Extrai o valor de itr do nome das pastas (P.O.G)\n",
    "                    itr = int(itr_subdir.replace(\"iteraction_\", \"\"))\n",
    "                    \n",
    "                    k_clusters =  read_csv_directory(clusters_subdirpath)\n",
    "                    \n",
    "                    # Insere o valor de K em todos os elementos dos arquivos CSV\n",
    "                    k_clusters.insert(loc=len(k_clusters.columns), column=\"k\", value=[k] * len(k_clusters))\n",
    "                    # Insere o valor de itr em todos os elementos dos arquivos CSV\n",
    "                    k_clusters.insert(loc=len(k_clusters.columns), column=\"iteraction\", value=[itr] * len(k_clusters))\n",
    "                    \n",
    "                    clusters.append(k_clusters)\n",
    "    \n",
    "    return pd.concat(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_results_from_csv(result_dirpath, overall_results_filename=\"clustering_overall_results.csv\"):\n",
    "    return read_csv_file(result_dirpath, overall_results_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
